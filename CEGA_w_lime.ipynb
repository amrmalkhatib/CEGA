{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686b464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openml\n",
    "from openml.datasets import edit_dataset, fork_dataset, get_dataset\n",
    "\n",
    "data = openml.datasets.get_dataset(41156)\n",
    "\n",
    "X, y, categorical_indicator, attribute_names = data.get_data(\n",
    "    target=data.default_target_attribute, dataset_format=\"dataframe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1054f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>V41</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V46</th>\n",
       "      <th>V47</th>\n",
       "      <th>V48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4147 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1  V2  V3     V4  V5  V6  V7  V8  V9  V10  ...  V39    V40  V41  V42  \\\n",
       "0      0   1   1   32.0   0   0   0   1   0  0.0  ...    0  404.0    1    0   \n",
       "1      0   0   1  133.0   0   0   1   0   0  0.0  ...    0  242.0    0    0   \n",
       "2      0   0   0  109.0   0   0   0   1   0  0.0  ...    0  404.0    1    0   \n",
       "3      0   0   0  113.0   0   0   0   1   0  0.0  ...    0  404.0    0    0   \n",
       "4      0   0   0  120.0   0   0   0   1   0  0.0  ...    0  303.0    0    1   \n",
       "...   ..  ..  ..    ...  ..  ..  ..  ..  ..  ...  ...  ...    ...  ...  ...   \n",
       "4142   0   0   0   50.0   1   0   0   1   1  0.0  ...    0  404.0    0    0   \n",
       "4143   0   0   0  144.0   0   0   0   1   1  0.0  ...    0  404.0    1    0   \n",
       "4144   0   0   0  129.0   0   0   0   0   0  0.0  ...    0  353.0    1    1   \n",
       "4145   0   0   0  225.0   0   0   1   1   0  0.0  ...    0  303.0    0    0   \n",
       "4146   0   0   0   46.0   0   0   0   1   0  0.0  ...    0  404.0    0    0   \n",
       "\n",
       "      V43  V44  V45  V46  V47  V48  \n",
       "0       0    0    0    0    0    0  \n",
       "1       0    0    0    0    0    0  \n",
       "2       0    0    0    0    0    0  \n",
       "3       0    1    0    1    0    0  \n",
       "4       0    0    0    0    0    0  \n",
       "...   ...  ...  ...  ...  ...  ...  \n",
       "4142    0    0    0    0    0    1  \n",
       "4143    0    0    0    0    0    0  \n",
       "4144    0    0    0    0    0    0  \n",
       "4145    0    0    0    0    0    0  \n",
       "4146    0    1    0    1    0    0  \n",
       "\n",
       "[4147 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nominal = [b for a, b in zip(categorical_indicator, attribute_names) if a]\n",
    "dummied_data = pd.get_dummies(X, columns=nominal)\n",
    "\n",
    "columns = dummied_data.columns\n",
    "updates = {}\n",
    "for col in columns:\n",
    "    if any(x in col for x in set(('[', ']', '=', '>', '<', ' ', '/', '(', ')', '-', '?'))):\n",
    "        updates[col] = col.replace('?', '_').replace('-', '_').replace(')', '_').replace('(', '_').replace(' ', '_').replace(',', '_').replace('[', '_').replace(']', '_').replace('<', 'less').replace('>', 'greater').replace('=', 'equal').replace('/', '_')\n",
    "dummied_data = dummied_data.rename(columns=updates)\n",
    "\n",
    "dummied_data.fillna(0, inplace=True)\n",
    "dummied_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab020cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "4142    0\n",
       "4143    0\n",
       "4144    0\n",
       "4145    0\n",
       "4146    1\n",
       "Name: class, Length: 4147, dtype: category\n",
       "Categories (2, object): ['0' < '1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2cd78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'1': 1, '0': 0}\n",
    "y = y.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67281076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (2488, 48)\n",
      " test shape: (829, 48)\n",
      " dev shape: (830, 48)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, left_out, y_train, y_left_out = train_test_split(dummied_data, y, test_size=0.4, random_state=42)\n",
    "X_test, X_dev, y_test, y_dev = train_test_split(left_out, y_left_out, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f'train shape: {X_train.shape}\\n test shape: {X_test.shape}\\n dev shape: {X_dev.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167f9775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 columns dropped\n",
      "train shape: (2488, 46)\n",
      " test shape: (829, 46)\n",
      " dev shape: (830, 46)\n"
     ]
    }
   ],
   "source": [
    "drop_list = [col for col in X_train.columns if sum(X_train[col]) <= 0]\n",
    "\n",
    "X_train.drop(drop_list, axis=1, inplace=True)\n",
    "X_test.drop(drop_list, axis=1, inplace=True)\n",
    "X_dev.drop(drop_list, axis=1, inplace=True)\n",
    "print(f'{len(drop_list)} columns dropped')\n",
    "print(f'train shape: {X_train.shape}\\n test shape: {X_test.shape}\\n dev shape: {X_dev.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9516fdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[15:49:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:49:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:49:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:49:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:49:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:49:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.0s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.0s\n",
      "[15:49:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:49:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.0s\n",
      "[15:49:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.0s\n",
      "[15:49:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:49:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.0s\n",
      "[15:49:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.0s\n",
      "[15:49:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:49:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:49:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:49:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.6s\n",
      "[15:49:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:49:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:49:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.0s\n",
      "[15:49:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.0s\n",
      "[15:49:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.0s\n",
      "[15:49:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.0s\n",
      "[15:49:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.1s\n",
      "[15:49:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.1s\n",
      "[15:49:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.1s\n",
      "[15:49:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.1s\n",
      "[15:49:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.1s\n",
      "[15:49:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.1s\n",
      "[15:49:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.1s\n",
      "[15:49:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.1s\n",
      "[15:49:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.1s\n",
      "[15:49:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.1s\n",
      "[15:49:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.1s\n",
      "[15:49:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.1s\n",
      "[15:49:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.1s\n",
      "[15:49:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.1s\n",
      "[15:49:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.1s\n",
      "[15:49:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.1s\n",
      "[15:49:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.1s\n",
      "[15:49:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=1.0, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:50:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:50:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:50:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:50:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:50:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.0s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.2s\n",
      "[15:50:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.1s\n",
      "[15:50:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.2s\n",
      "[15:50:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.1s\n",
      "[15:50:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.2s\n",
      "[15:50:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.1s\n",
      "[15:50:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.1s\n",
      "[15:50:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.1s\n",
      "[15:50:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.1s\n",
      "[15:50:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.1s\n",
      "[15:50:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.1, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.1s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.1s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.2s\n",
      "[15:50:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.2s\n",
      "[15:50:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.2s\n",
      "[15:50:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.2s\n",
      "[15:50:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.2s\n",
      "[15:50:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.2s\n",
      "[15:50:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.2s\n",
      "[15:50:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.2s\n",
      "[15:50:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.2s\n",
      "[15:50:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.2s\n",
      "[15:50:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.2s\n",
      "[15:50:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.2s\n",
      "[15:50:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.2s\n",
      "[15:50:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.2s\n",
      "[15:50:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.2s\n",
      "[15:50:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.2s\n",
      "[15:50:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.2s\n",
      "[15:50:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.2s\n",
      "[15:50:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.2s\n",
      "[15:50:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.2s\n",
      "[15:50:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.2s\n",
      "[15:50:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.2s\n",
      "[15:50:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.2s\n",
      "[15:50:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.3s\n",
      "[15:50:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.3s\n",
      "[15:50:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:50:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:50:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:50:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.0s\n",
      "[15:50:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=10; total time=   0.1s\n",
      "[15:50:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:50:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.1s\n",
      "[15:50:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.0s\n",
      "[15:50:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.1s\n",
      "[15:50:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=1; total time=   0.1s\n",
      "[15:50:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=100, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=10; total time=   0.1s\n",
      "[15:50:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=1; total time=   0.1s\n",
      "[15:50:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.2s\n",
      "[15:50:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.1; total time=   0.1s\n",
      "[15:50:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.2s\n",
      "[15:50:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.2s\n",
      "[15:50:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.01; total time=   0.1s\n",
      "[15:50:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.1s\n",
      "[15:50:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.2s\n",
      "[15:50:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=250, reg_lambda=0.001; total time=   0.2s\n",
      "[15:50:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.2s\n",
      "[15:50:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.2s\n",
      "[15:50:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.2s\n",
      "[15:50:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.2s\n",
      "[15:50:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=10; total time=   0.2s\n",
      "[15:50:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.2s\n",
      "[15:50:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.2s\n",
      "[15:50:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.2s\n",
      "[15:50:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.3s\n",
      "[15:50:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=1; total time=   0.2s\n",
      "[15:50:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.3s\n",
      "[15:50:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.3s\n",
      "[15:50:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.3s\n",
      "[15:50:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.3s\n",
      "[15:50:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.1; total time=   0.3s\n",
      "[15:50:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.3s\n",
      "[15:50:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.3s\n",
      "[15:50:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.3s\n",
      "[15:50:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.3s\n",
      "[15:50:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.01; total time=   0.3s\n",
      "[15:50:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.3s\n",
      "[15:50:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.4s\n",
      "[15:50:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.3s\n",
      "[15:50:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.3s\n",
      "[15:50:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.001, max_depth=70000, n_estimators=500, reg_lambda=0.001; total time=   0.4s\n",
      "[15:50:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9927124907612713 {'learning_rate': 1.0, 'max_depth': 70000, 'n_estimators': 250, 'reg_lambda': 10}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xg_boost = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False)\n",
    "\n",
    "clf = GridSearchCV(xg_boost,{'learning_rate': [1.0, 0.1, 0.01, 0.001],\n",
    "                        'max_depth': [70000],\n",
    "                        'n_estimators': [100, 250, 500],\n",
    "                       'reg_lambda': [10, 1, 0.1, 0.01, 0.001]}, \n",
    "                        verbose=2, \n",
    "                        error_score='raise')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_, clf.best_params_)\n",
    "xgb_clf = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad16e18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:36:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB test_acc: 0.8528347406513872\n",
      "recall: 0.78938225505317\n",
      "precision: 0.7958226839711886\n",
      "f_score: 0.7925084934924256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amak2/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from helper_func import plot_roc\n",
    "\n",
    "xg_boost = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, \n",
    "                             learning_rate=0.1, max_depth=7000, n_estimators= 250, reg_lambda=1)\n",
    "\n",
    "xgb_clf = xg_boost.fit(X_train, y_train)\n",
    "test_ac = xgb_clf.score(X_test, y_test)\n",
    "pred = xgb_clf.predict(X_test)\n",
    "f_score = f1_score(y_test, pred, average='macro')\n",
    "prec = precision_score(y_test, pred, average='macro')\n",
    "recall = recall_score(y_test, pred, average='macro')\n",
    "\n",
    "print(f'XGB test_acc: {test_ac}\\nrecall: {recall}\\nprecision: {prec}\\nf_score: {f_score}\\n')\n",
    "plot_roc(xgb_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49a99e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:36:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB test_acc: 0.8528347406513872\n",
      "recall: 0.78938225505317\n",
      "precision: 0.7958226839711886\n",
      "f_score: 0.7925084934924256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amak2/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = list(X_train.columns)\n",
    "values = list(xgb_clf.feature_importances_)\n",
    "\n",
    "assert len(names) == len(values)\n",
    "\n",
    "important_features = [p[0] for p in zip(names, values) if p[1] > 0]\n",
    "\n",
    "to_drop = []\n",
    "for cl in names:\n",
    "    if cl not in important_features:\n",
    "        to_drop.append(cl)\n",
    "\n",
    "    \n",
    "X_train.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "X_test.drop(to_drop, axis=1, inplace=True)\n",
    "X_dev.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "clf = xg_boost.fit(X_train, y_train)\n",
    "\n",
    "test_ac = clf.score(X_test, y_test)\n",
    "pred = clf.predict(X_test)\n",
    "f_score = f1_score(y_test, pred, average='macro')\n",
    "prec = precision_score(y_test, pred, average='macro')\n",
    "recall = recall_score(y_test, pred, average='macro')\n",
    "\n",
    "print(f'XGB test_acc: {test_ac}\\nrecall: {recall}\\nprecision: {prec}\\nf_score: {f_score}\\n')\n",
    "plot_roc(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4af82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "from __future__ import print_function\n",
    "np.random.seed(1)\n",
    "    \n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, \n",
    "                                                   feature_names=list(X_train.columns), \n",
    "                                                   class_names=['0', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b21750c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of cores: 16\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count, Queue\n",
    "from helper_func import *\n",
    "\n",
    "num_cores = cpu_count()\n",
    "print(f'num of cores: {num_cores}')\n",
    "        \n",
    "if len(intervals_dict) == 0:\n",
    "        compute_intervals(intervals_dict, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b6b2b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 830/830 [43:58<00:00,  3.18s/it]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "pred = xgb_clf.predict(X_dev)\n",
    "\n",
    "pos_label = '1'\n",
    "neg_label = '0'\n",
    "\n",
    "itemset = set()\n",
    "encoded_vals = []\n",
    "summed_values = {}\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "shap_threshold = 0.001\n",
    "\n",
    "p = Pool(num_cores)\n",
    "\n",
    "for feature in X_train.columns.to_list():\n",
    "    if feature in intervals_dict:\n",
    "        intervals = intervals_dict[feature]\n",
    "        for interval in intervals:\n",
    "            if interval != interval: continue\n",
    "            left = interval.left\n",
    "            right = interval.right\n",
    "            name = f'{left}<{feature}<={right}'\n",
    "            itemset.add(name)\n",
    "    else:\n",
    "        itemset.add(feature)\n",
    "\n",
    "itemset.add(pos_label)\n",
    "itemset.add(neg_label)\n",
    "\n",
    "for indx in tqdm(range(len(pred))):\n",
    "    \n",
    "    pos_queue.put(pos_label)\n",
    "    neg_queue.put(neg_label)\n",
    "    \n",
    "    exp = explainer.explain_instance(X_dev.values[indx], clf.predict_proba, num_features=num_features)\n",
    "    lime_names = [clean_name(name) for name, val in exp.as_list()]\n",
    "    lime_vals = [val for name, val in exp.as_list()]\n",
    "    \n",
    "    instance_features = X_dev.iloc[[indx]].to_dict(orient='records')[0]\n",
    "    feature_vals = [instance_features[name] for name in lime_names]\n",
    "    \n",
    "    zipped = zip(lime_vals, feature_vals,\n",
    "                 lime_names, [shap_threshold]*len(lime_names))\n",
    "\n",
    "    p.map(get_relevant_features, zipped)\n",
    "    \n",
    "    append_to_encoded_vals(pos_queue, itemset, encoded_vals)\n",
    "    append_to_encoded_vals(neg_queue, itemset, encoded_vals)\n",
    "\n",
    "ohe_df = pd.DataFrame(encoded_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e01fc30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>129.6&lt;V10&lt;=259.2</th>\n",
       "      <th>V7</th>\n",
       "      <th>188.19&lt;V25&lt;=351.0</th>\n",
       "      <th>V35</th>\n",
       "      <th>207.8&lt;V40&lt;=405.6</th>\n",
       "      <th>V29</th>\n",
       "      <th>V6</th>\n",
       "      <th>V33</th>\n",
       "      <th>V45</th>\n",
       "      <th>374.2&lt;V4&lt;=554.8</th>\n",
       "      <th>...</th>\n",
       "      <th>-0.999&lt;V32&lt;=199.8</th>\n",
       "      <th>-0.648&lt;V10&lt;=129.6</th>\n",
       "      <th>405.6&lt;V40&lt;=603.4</th>\n",
       "      <th>V9</th>\n",
       "      <th>351.0&lt;V25&lt;=513.0</th>\n",
       "      <th>V2</th>\n",
       "      <th>V26</th>\n",
       "      <th>1</th>\n",
       "      <th>V18</th>\n",
       "      <th>V31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1660 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      129.6<V10<=259.2  V7  188.19<V25<=351.0  V35  207.8<V40<=405.6  V29  V6  \\\n",
       "0                    0   0                  0    0                 0    0   0   \n",
       "1                    0   1                  0    1                 0    1   1   \n",
       "2                    0   0                  0    0                 0    0   0   \n",
       "3                    0   1                  0    1                 0    1   1   \n",
       "4                    0   0                  0    0                 0    1   1   \n",
       "...                ...  ..                ...  ...               ...  ...  ..   \n",
       "1655                 0   1                  0    1                 1    0   0   \n",
       "1656                 0   0                  0    0                 0    0   1   \n",
       "1657                 0   1                  1    1                 0    0   0   \n",
       "1658                 0   0                  0    0                 0    1   1   \n",
       "1659                 0   1                  0    1                 1    0   0   \n",
       "\n",
       "      V33  V45  374.2<V4<=554.8  ...  -0.999<V32<=199.8  -0.648<V10<=129.6  \\\n",
       "0       0    0                0  ...                  1                  1   \n",
       "1       1    1                0  ...                  0                  0   \n",
       "2       0    0                0  ...                  1                  1   \n",
       "3       1    1                0  ...                  0                  0   \n",
       "4       0    0                0  ...                  1                  1   \n",
       "...   ...  ...              ...  ...                ...                ...   \n",
       "1655    1    1                0  ...                  0                  0   \n",
       "1656    0    0                0  ...                  1                  1   \n",
       "1657    1    1                0  ...                  0                  0   \n",
       "1658    1    0                0  ...                  1                  1   \n",
       "1659    0    1                0  ...                  0                  0   \n",
       "\n",
       "      405.6<V40<=603.4  V9  351.0<V25<=513.0  V2  V26  1  V18  V31  \n",
       "0                    1   1                 1   1    1  1    1    1  \n",
       "1                    0   0                 0   0    0  0    0    0  \n",
       "2                    1   1                 0   0    0  1    1    0  \n",
       "3                    0   0                 0   1    1  0    0    1  \n",
       "4                    0   1                 0   1    1  1    1    1  \n",
       "...                ...  ..               ...  ..  ... ..  ...  ...  \n",
       "1655                 0   0                 0   0    0  0    0    0  \n",
       "1656                 0   1                 0   1    1  1    1    1  \n",
       "1657                 0   0                 0   0    0  0    0    0  \n",
       "1658                 0   1                 1   1    0  1    1    1  \n",
       "1659                 0   0                 0   0    1  0    0    0  \n",
       "\n",
       "[1660 rows x 64 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52c75966",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_items = apriori(ohe_df, min_support=(10/len(pred)), use_colnames=True, max_len=3)\n",
    "all_rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.7, support_only=False)\n",
    "\n",
    "freq_items = apriori(ohe_df.loc[ohe_df[pos_label] == 1], min_support=(10/len(pred)), use_colnames=True, max_len=3)\n",
    "pos_rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.6, support_only=False)\n",
    "\n",
    "freq_items = apriori(ohe_df.loc[ohe_df[neg_label] == 1], min_support=(10/len(pred)), use_colnames=True, max_len=3)\n",
    "neg_rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.6, support_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47036807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "positive = all_rules[all_rules['consequents'] == {pos_label}]\n",
    "positive = positive[positive['confidence'] == 1]\n",
    "positive = positive.sort_values(['confidence', 'support'], ascending=[False, False])\n",
    "\n",
    "seen = set()\n",
    "dropped = set()\n",
    "indexes_to_drop = []\n",
    "\n",
    "positive = positive.reset_index(drop=True)\n",
    "print(len(positive))\n",
    "for i in positive.index:\n",
    "    new_rule = positive.loc[[i]]['antecedents'].values[0]\n",
    "    \n",
    "    for seen_rule in seen:\n",
    "        if seen_rule.issubset(new_rule):#new_rule.issubset(seen_rule) or seen_rule.issubset(new_rule):\n",
    "            indexes_to_drop.append(i)\n",
    "            break\n",
    "    else:\n",
    "        seen.add(new_rule)\n",
    "\n",
    "positive.drop(positive.index[indexes_to_drop], inplace=True )\n",
    "print(len(positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b83958b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "negative = all_rules[all_rules['consequents'] == {neg_label}]\n",
    "negative = negative[negative['confidence'] == 1]\n",
    "\n",
    "negative = negative.sort_values(['confidence', 'support'], ascending=[False, False])\n",
    "\n",
    "seen = set()\n",
    "dropped = set()\n",
    "indexes_to_drop = []\n",
    "\n",
    "negative = negative.reset_index(drop=True)\n",
    "print(len(negative))\n",
    "for i in negative.index:\n",
    "    new_rule = negative.loc[[i]]['antecedents'].values[0]\n",
    "    \n",
    "    for seen_rule in seen:\n",
    "        if seen_rule.issubset(new_rule):#new_rule.issubset(seen_rule) or seen_rule.issubset(new_rule):\n",
    "            indexes_to_drop.append(i)\n",
    "            break\n",
    "    else:\n",
    "        seen.add(new_rule)\n",
    "\n",
    "negative.drop(negative.index[indexes_to_drop], inplace=True )\n",
    "print(len(negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6f57889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemset</th>\n",
       "      <th>label</th>\n",
       "      <th>num-items</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>antecedent support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(V44)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(V46)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(V9)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(V18)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(V13)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(V5)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(V42)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(V16)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.498193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.498193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(-0.999&lt;V32&lt;=199.8)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.496988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.496988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(V35, V17)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.483735</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.483735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(V35, V45)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.483133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.483133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(V17, V45)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.481325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.481325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(V33, V17)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.480120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.480120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(V33, V45)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.478916</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(V23, V35)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.477108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.477108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(V23, V45)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.475301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.475301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(V23, V33)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.473494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.473494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(V35, V27)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.417470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.417470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(V27, V45)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.417470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.417470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(V27, V33)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.415060</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.415060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(V35, V41)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.384337</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.384337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(V45, V19)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.374096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.374096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(V33, V19)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.372892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.372892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(V35, 12.097&lt;V4&lt;=193.6)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.354819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.354819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(207.8&lt;V40&lt;=405.6)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.302410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.302410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(V35, 436.8&lt;V15&lt;=624.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.290361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.290361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(436.8&lt;V15&lt;=624.2, V45)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.288554</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.288554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(V17, 436.8&lt;V15&lt;=624.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.287952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(V33, 436.8&lt;V15&lt;=624.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.286145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.286145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(V23, 436.8&lt;V15&lt;=624.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.284940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.284940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(436.8&lt;V15&lt;=624.2, V41)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.233735</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.233735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(188.19&lt;V25&lt;=351.0, V45)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.154217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(188.19&lt;V25&lt;=351.0, V35)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.152410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(188.19&lt;V25&lt;=351.0, V17)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.151205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(V23, 188.19&lt;V25&lt;=351.0)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.151205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(188.19&lt;V25&lt;=351.0, V33)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(811.6&lt;V15&lt;=999.0)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(405.6&lt;V40&lt;=603.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115060</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.115060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(188.19&lt;V25&lt;=351.0, 12.097&lt;V4&lt;=193.6)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.109036</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.109036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(188.19&lt;V25&lt;=351.0, 436.8&lt;V15&lt;=624.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.107831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.107831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(513.0&lt;V25&lt;=675.0)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.099398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(193.6&lt;V4&lt;=374.2)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(9.011&lt;V40&lt;=207.8)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(603.4&lt;V40&lt;=801.2)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(675.0&lt;V25&lt;=837.0)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(624.2&lt;V15&lt;=811.6)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(249.4&lt;V15&lt;=436.8)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(388.8&lt;V10&lt;=518.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.019880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  itemset label  num-items   support  \\\n",
       "0                                   (V44)     1          1  0.500000   \n",
       "1                                   (V46)     1          1  0.500000   \n",
       "2                                    (V9)     1          1  0.500000   \n",
       "3                                   (V18)     1          1  0.500000   \n",
       "12                                  (V13)     0          1  0.500000   \n",
       "13                                   (V5)     0          1  0.500000   \n",
       "14                                  (V42)     0          1  0.500000   \n",
       "15                                  (V16)     0          1  0.498193   \n",
       "4                     (-0.999<V32<=199.8)     1          1  0.496988   \n",
       "16                             (V35, V17)     0          2  0.483735   \n",
       "17                             (V35, V45)     0          2  0.483133   \n",
       "18                             (V17, V45)     0          2  0.481325   \n",
       "19                             (V33, V17)     0          2  0.480120   \n",
       "20                             (V33, V45)     0          2  0.478916   \n",
       "21                             (V23, V35)     0          2  0.477108   \n",
       "22                             (V23, V45)     0          2  0.475301   \n",
       "23                             (V23, V33)     0          2  0.473494   \n",
       "24                             (V35, V27)     0          2  0.417470   \n",
       "25                             (V27, V45)     0          2  0.417470   \n",
       "26                             (V27, V33)     0          2  0.415060   \n",
       "27                             (V35, V41)     0          2  0.384337   \n",
       "28                             (V45, V19)     0          2  0.374096   \n",
       "29                             (V33, V19)     0          2  0.372892   \n",
       "30                (V35, 12.097<V4<=193.6)     0          2  0.354819   \n",
       "31                     (207.8<V40<=405.6)     0          1  0.302410   \n",
       "32                (V35, 436.8<V15<=624.2)     0          2  0.290361   \n",
       "33                (436.8<V15<=624.2, V45)     0          2  0.288554   \n",
       "34                (V17, 436.8<V15<=624.2)     0          2  0.287952   \n",
       "35                (V33, 436.8<V15<=624.2)     0          2  0.286145   \n",
       "36                (V23, 436.8<V15<=624.2)     0          2  0.284940   \n",
       "37                (436.8<V15<=624.2, V41)     0          2  0.233735   \n",
       "38               (188.19<V25<=351.0, V45)     0          2  0.154217   \n",
       "39               (188.19<V25<=351.0, V35)     0          2  0.152410   \n",
       "40               (188.19<V25<=351.0, V17)     0          2  0.151205   \n",
       "41               (V23, 188.19<V25<=351.0)     0          2  0.151205   \n",
       "42               (188.19<V25<=351.0, V33)     0          2  0.150000   \n",
       "5                      (811.6<V15<=999.0)     1          1  0.133133   \n",
       "6                      (405.6<V40<=603.4)     1          1  0.115060   \n",
       "43  (188.19<V25<=351.0, 12.097<V4<=193.6)     0          2  0.109036   \n",
       "44  (188.19<V25<=351.0, 436.8<V15<=624.2)     0          2  0.107831   \n",
       "7                      (513.0<V25<=675.0)     1          1  0.099398   \n",
       "8                       (193.6<V4<=374.2)     1          1  0.070482   \n",
       "45                     (9.011<V40<=207.8)     0          1  0.043373   \n",
       "9                      (603.4<V40<=801.2)     1          1  0.031325   \n",
       "10                     (675.0<V25<=837.0)     1          1  0.030120   \n",
       "46                     (624.2<V15<=811.6)     0          1  0.028313   \n",
       "47                     (249.4<V15<=436.8)     0          1  0.024699   \n",
       "11                     (388.8<V10<=518.4)     1          1  0.019880   \n",
       "\n",
       "    confidence  antecedent support  \n",
       "0          1.0            0.500000  \n",
       "1          1.0            0.500000  \n",
       "2          1.0            0.500000  \n",
       "3          1.0            0.500000  \n",
       "12         1.0            0.500000  \n",
       "13         1.0            0.500000  \n",
       "14         1.0            0.500000  \n",
       "15         1.0            0.498193  \n",
       "4          1.0            0.496988  \n",
       "16         1.0            0.483735  \n",
       "17         1.0            0.483133  \n",
       "18         1.0            0.481325  \n",
       "19         1.0            0.480120  \n",
       "20         1.0            0.478916  \n",
       "21         1.0            0.477108  \n",
       "22         1.0            0.475301  \n",
       "23         1.0            0.473494  \n",
       "24         1.0            0.417470  \n",
       "25         1.0            0.417470  \n",
       "26         1.0            0.415060  \n",
       "27         1.0            0.384337  \n",
       "28         1.0            0.374096  \n",
       "29         1.0            0.372892  \n",
       "30         1.0            0.354819  \n",
       "31         1.0            0.302410  \n",
       "32         1.0            0.290361  \n",
       "33         1.0            0.288554  \n",
       "34         1.0            0.287952  \n",
       "35         1.0            0.286145  \n",
       "36         1.0            0.284940  \n",
       "37         1.0            0.233735  \n",
       "38         1.0            0.154217  \n",
       "39         1.0            0.152410  \n",
       "40         1.0            0.151205  \n",
       "41         1.0            0.151205  \n",
       "42         1.0            0.150000  \n",
       "5          1.0            0.133133  \n",
       "6          1.0            0.115060  \n",
       "43         1.0            0.109036  \n",
       "44         1.0            0.107831  \n",
       "7          1.0            0.099398  \n",
       "8          1.0            0.070482  \n",
       "45         1.0            0.043373  \n",
       "9          1.0            0.031325  \n",
       "10         1.0            0.030120  \n",
       "46         1.0            0.028313  \n",
       "47         1.0            0.024699  \n",
       "11         1.0            0.019880  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive['num-items'] = positive['antecedents'].map(lambda x: len(x))\n",
    "negative['num-items'] = negative['antecedents'].map(lambda x: len(x))\n",
    "positive['consequents'] = positive['consequents'].map(lambda x: pos_label)\n",
    "negative['consequents'] = negative['consequents'].map(lambda x: neg_label)\n",
    "\n",
    "both = positive.append(negative, ignore_index=True)\n",
    "\n",
    "discr_rules = both[['antecedents', 'consequents', 'num-items', 'support', 'confidence', 'antecedent support']].sort_values(\n",
    "    ['support', 'confidence', 'num-items'], ascending=[False, False, False])\n",
    "\n",
    "discr_rules = discr_rules.rename(columns={\"antecedents\": \"itemset\", \"consequents\": \"label\"})\n",
    "\n",
    "discr_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73ee0fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "11\n",
      "84\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "rev_positive = pos_rules[pos_rules['antecedents'] == {pos_label}]\n",
    "rev_positive = rev_positive[rev_positive['confidence'] >= 0.7]\n",
    "rev_positive = rev_positive.sort_values(['confidence', 'support'], ascending=[False, False])\n",
    "\n",
    "seen = set()\n",
    "dropped = set()\n",
    "indexes_to_drop = []\n",
    "\n",
    "rev_positive = rev_positive.reset_index(drop=True)\n",
    "print(len(rev_positive))\n",
    "for i in rev_positive.index:\n",
    "    new_rule = rev_positive.loc[[i]]['consequents'].values[0]\n",
    "    \n",
    "    for seen_rule, indx in seen:\n",
    "        if seen_rule.issubset(new_rule):\n",
    "            indexes_to_drop.append(i)\n",
    "            break\n",
    "    else:\n",
    "        seen.add((new_rule, i))\n",
    "\n",
    "rev_positive.drop(rev_positive.index[indexes_to_drop], inplace=True )\n",
    "print(len(rev_positive))\n",
    "\n",
    "\n",
    "\n",
    "rev_negative = neg_rules[neg_rules['antecedents'] == {neg_label}]\n",
    "rev_negative = rev_negative[rev_negative['confidence'] >= 0.7]\n",
    "rev_negative = rev_negative.sort_values(['confidence', 'support'], ascending=[False, False])\n",
    "\n",
    "seen = set()\n",
    "dropped = set()\n",
    "indexes_to_drop = []\n",
    "\n",
    "rev_negative = rev_negative.reset_index(drop=True)\n",
    "print(len(rev_negative))\n",
    "for i in rev_negative.index:\n",
    "    new_rule = rev_negative.loc[[i]]['consequents'].values[0]\n",
    "    \n",
    "    for seen_rule, indx in seen:\n",
    "        if seen_rule.issubset(new_rule):\n",
    "            indexes_to_drop.append(i)\n",
    "            break\n",
    "    else:\n",
    "        seen.add((new_rule, i))\n",
    "\n",
    "rev_negative.drop(rev_negative.index[indexes_to_drop], inplace=True )\n",
    "print(len(rev_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a01f772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>itemset</th>\n",
       "      <th>num-items</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>consequent support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(V44)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(V46)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(V9)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>(V18)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>(V13)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>(V5)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>(V42)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>(V16)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996386</td>\n",
       "      <td>0.996386</td>\n",
       "      <td>0.996386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>(-0.999&lt;V32&lt;=199.8)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.993976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>(V35)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985542</td>\n",
       "      <td>0.985542</td>\n",
       "      <td>0.985542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>(V17)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981928</td>\n",
       "      <td>0.981928</td>\n",
       "      <td>0.981928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>(V45)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980723</td>\n",
       "      <td>0.980723</td>\n",
       "      <td>0.980723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>(V33)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977108</td>\n",
       "      <td>0.977108</td>\n",
       "      <td>0.977108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>(V23)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968675</td>\n",
       "      <td>0.968675</td>\n",
       "      <td>0.968675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>(V22)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944578</td>\n",
       "      <td>0.944578</td>\n",
       "      <td>0.944578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>(-0.648&lt;V10&lt;=129.6)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.878313</td>\n",
       "      <td>0.878313</td>\n",
       "      <td>0.878313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>(V29)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872289</td>\n",
       "      <td>0.872289</td>\n",
       "      <td>0.872289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>(V27)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.848193</td>\n",
       "      <td>0.848193</td>\n",
       "      <td>0.848193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>(V2)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.821687</td>\n",
       "      <td>0.821687</td>\n",
       "      <td>0.821687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>(V41)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.781928</td>\n",
       "      <td>0.781928</td>\n",
       "      <td>0.781928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>(V19)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766265</td>\n",
       "      <td>0.766265</td>\n",
       "      <td>0.766265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>(V12)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.734940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>(V31)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724096</td>\n",
       "      <td>0.724096</td>\n",
       "      <td>0.724096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>(12.097&lt;V4&lt;=193.6)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.720482</td>\n",
       "      <td>0.720482</td>\n",
       "      <td>0.720482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label              itemset  num-items   support  confidence  \\\n",
       "0      1                (V44)          1  1.000000    1.000000   \n",
       "1      1                (V46)          1  1.000000    1.000000   \n",
       "2      1                 (V9)          1  1.000000    1.000000   \n",
       "3      1                (V18)          1  1.000000    1.000000   \n",
       "11     0                (V13)          1  1.000000    1.000000   \n",
       "12     0                 (V5)          1  1.000000    1.000000   \n",
       "13     0                (V42)          1  1.000000    1.000000   \n",
       "14     0                (V16)          1  0.996386    0.996386   \n",
       "4      1  (-0.999<V32<=199.8)          1  0.993976    0.993976   \n",
       "15     0                (V35)          1  0.985542    0.985542   \n",
       "16     0                (V17)          1  0.981928    0.981928   \n",
       "17     0                (V45)          1  0.980723    0.980723   \n",
       "18     0                (V33)          1  0.977108    0.977108   \n",
       "19     0                (V23)          1  0.968675    0.968675   \n",
       "5      1                (V22)          1  0.944578    0.944578   \n",
       "6      1  (-0.648<V10<=129.6)          1  0.878313    0.878313   \n",
       "7      1                (V29)          1  0.872289    0.872289   \n",
       "20     0                (V27)          1  0.848193    0.848193   \n",
       "8      1                 (V2)          1  0.821687    0.821687   \n",
       "21     0                (V41)          1  0.781928    0.781928   \n",
       "22     0                (V19)          1  0.766265    0.766265   \n",
       "9      1                (V12)          1  0.734940    0.734940   \n",
       "10     1                (V31)          1  0.724096    0.724096   \n",
       "23     0   (12.097<V4<=193.6)          1  0.720482    0.720482   \n",
       "\n",
       "    consequent support  \n",
       "0             1.000000  \n",
       "1             1.000000  \n",
       "2             1.000000  \n",
       "3             1.000000  \n",
       "11            1.000000  \n",
       "12            1.000000  \n",
       "13            1.000000  \n",
       "14            0.996386  \n",
       "4             0.993976  \n",
       "15            0.985542  \n",
       "16            0.981928  \n",
       "17            0.980723  \n",
       "18            0.977108  \n",
       "19            0.968675  \n",
       "5             0.944578  \n",
       "6             0.878313  \n",
       "7             0.872289  \n",
       "20            0.848193  \n",
       "8             0.821687  \n",
       "21            0.781928  \n",
       "22            0.766265  \n",
       "9             0.734940  \n",
       "10            0.724096  \n",
       "23            0.720482  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_positive['num-items'] = rev_positive['consequents'].map(lambda x: len(x))\n",
    "rev_negative['num-items'] = rev_negative['consequents'].map(lambda x: len(x))\n",
    "rev_positive['antecedents'] = rev_positive['antecedents'].map(lambda x: pos_label)\n",
    "rev_negative['antecedents'] = rev_negative['antecedents'].map(lambda x: neg_label)\n",
    "\n",
    "rev_both = rev_positive.append(rev_negative, ignore_index=True)\n",
    "\n",
    "chr_rules = rev_both[['antecedents', 'consequents', 'num-items', 'support', \n",
    "                          'confidence', 'consequent support']].sort_values(\n",
    "    ['support', 'confidence', 'num-items'], ascending=[False, False, False])\n",
    "\n",
    "chr_rules = chr_rules.rename(columns={\"antecedents\": \"label\", \"consequents\": \"itemset\"})\n",
    "\n",
    "chr_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26eada9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 829/829 [00:02<00:00, 299.24it/s]\n",
      "Acc: 0.8709288299155609\n",
      "macro rules recall: 0.8094026952567464\n",
      "macro rules prec: 0.8178969715571927\n",
      "macro rules f1_score: 0.8135085074667658\n",
      "188 181\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2817133263222955]\n",
      "coverage: 1.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rules_model import *\n",
    "\n",
    "dev_pred = xgb_clf.predict(X_dev)\n",
    "rules_model = RulesModel(ohe_df, discr_rules, y_dev, pos_label, neg_label)\n",
    "\n",
    "test_pred = xgb_clf.predict(X_test)\n",
    "rules_test_sol = rules_model.eval_rules(X_test, test_pred, alpha=10, beta =1, decision_thr=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adb792e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 829/829 [00:02<00:00, 290.00it/s]\n",
      "Acc: 0.8202653799758746\n",
      "macro rules recall: 0.8236299664752547\n",
      "macro rules prec: 0.7569373072970196\n",
      "macro rules f1_score: 0.776155863266264\n",
      "188 273\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04107975860082796]\n",
      "coverage: 1.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rules_model = RulesModel(ohe_df, chr_rules, y_dev, pos_label, neg_label)\n",
    "\n",
    "test_pred = xgb_clf.predict(X_test)\n",
    "rules_test_sol = rules_model.eval_rules(X_test, test_pred, alpha=30, beta=1, decision_thr=0.041)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ca66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}